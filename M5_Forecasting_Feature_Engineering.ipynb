{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtIEsjuonnmt"
   },
   "source": [
    "<h1><b>M5 Forecasting: Feature Engineering</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Contents**\n",
    "\n",
    "<h3> 1. Reading the Data</h3> \n",
    "\n",
    "<h3> 2. Data Preprocessing </h3> \n",
    "\n",
    "<h3> 3. Feature Engineering </h3> \n",
    "\n",
    "<h3> 4. References</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x05-P_Ohnp-Q"
   },
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random \n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMxZRK7L3-Yq"
   },
   "source": [
    "# 1. Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SEvC-AssyWEx"
   },
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv('sales_train_evaluation.csv')\n",
    "df_price = pd.read_csv('sell_prices.csv')\n",
    "df_cal = pd.read_csv('calendar.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Manipulation \n",
    "- Sales Data\n",
    "    - Convert the day column names to numeric \n",
    "    \n",
    "    - Add day columns for evaluation period (1942 to 1969) \n",
    "- Calender Data\n",
    "    - Convert day column values from object to integer dtype \n",
    "- Price Data\n",
    "    - Create id feature combining store and item id  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sales Data\n",
    "df_sales.columns = list(df_sales.columns[:6]) + list(range(1,1942))\n",
    "\n",
    "for day in range(1942, 1970):\n",
    "    df_sales[day] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calendar Data\n",
    "df_cal[\"d\"]= df_cal[\"d\"].apply(lambda x: int(x.split(\"_\")[1])).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price Data\n",
    "df_price[\"id\"] = df_price[\"item_id\"] + \"_\" + df_price[\"store_id\"] + \"_evaluation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature Creation\n",
    "- Basic Time Based Features\n",
    "    - Derive quarter, week and day features from date\n",
    "    - Create a binary feature which identifies weekend days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimeFeat = [\"quarter\", \"week\", \"day\"] \n",
    "\n",
    "for feat in datetimeFeat:\n",
    "    df_cal[feat] = getattr(df_cal['date'].dt, feat).astype('int8')\n",
    "\n",
    "df_cal.rename(columns = {'day':'day_of_month'}, inplace=True)\n",
    "\n",
    "df_cal['is_weekend'] = df_cal[\"weekday\"].apply(lambda x: 1 if x in ['Saturday','Sunday'] else 0).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Reduce Memory Usage\n",
    "- Define a downcast function which can be leveraged at any stage \n",
    "- Downcast the dataframes to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refer - https://stackoverflow.com/questions/1658714/how-to-get-the-range-of-valid-numpy-data-types\n",
    "def downcast(data):\n",
    "    cols = data.columns\n",
    "    for col in cols:\n",
    "        if data[col].dtype == object:\n",
    "            if col =='date':\n",
    "                data[col] = pd.to_datetime(data[col])\n",
    "            else: \n",
    "                data[col] = data[col].astype('category') \n",
    " \n",
    "        #only check the upper value because we only have positive values in dataframes\n",
    "        elif data[col].dtype == int: \n",
    "            if data[col].max() < np.iinfo('int8').max:\n",
    "                data[col] = data[col].astype('int8')\n",
    "\n",
    "            elif data[col].max() < np.iinfo('int16').max:\n",
    "                data[col] = data[col].astype('int16')\n",
    "\n",
    "            elif data[col].max() < np.iinfo('int32').max:\n",
    "                data[col] = data[col].astype('int32')\n",
    "            else:\n",
    "                data[col] = data[col].astype('int64')\n",
    "\n",
    "        elif data[col].dtype == float:\n",
    "            if data[col].max() < np.finfo('float16').max:\n",
    "                data[col] = data[col].astype('float16')\n",
    "            elif data[col].max() < np.finfo('float32').max:\n",
    "                data[col] = data[col].astype('float32')\n",
    "            else:\n",
    "                data[col] = data[col].astype('float64')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.6 s, sys: 1min 18s, total: 2min 16s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sales = downcast(df_sales)\n",
    "df_cal = downcast(df_cal)\n",
    "df_price = downcast(df_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Encode Categorical Features\n",
    "- Save category codes in dictionary\n",
    "- Perform feature encoding on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save category codes\n",
    "sales_catFeat = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "cal_catFeat = ['event_name_1','event_type_1','event_name_2','event_type_2']\n",
    "\n",
    "#refer - https://stackoverflow.com/questions/6181935/how-do-you-create-different-variable-names-while-in-a-loop\n",
    "for feat in sales_catFeat: \n",
    "    exec(f'dict_{feat} = dict(zip(df_sales[feat], df_sales[feat].cat.codes))')\n",
    "                 \n",
    "for feat in cal_catFeat: \n",
    "    exec(f'dict_{feat} = dict(zip(df_cal[feat], df_cal[feat].cat.codes))')\n",
    "\n",
    "#refer - https://www.pythonforbeginners.com/basics/convert-string-to-variable-name-in-python#:~:text=is%20pythonforbeginners.com-,String%20Into%20Variable%20Name%20in%20Python%20Using%20the%20vars(),like%20the%20globals()%20function.\n",
    "for feat in sales_catFeat+cal_catFeat:\n",
    "    varStr = f'dict_{feat}'\n",
    "    var = vars()\n",
    "    pickle.dump(var[varStr], open(f'saved_dicts/dict_{feat}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature encoding\n",
    "for col in sales_catFeat:\n",
    "    df_sales[col] = df_sales[col].cat.codes\n",
    "    if col == 'id':\n",
    "        df_price[col] = df_price[col].cat.codes\n",
    "        \n",
    "for col in cal_catFeat:\n",
    "    df_cal[col] = df_cal[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72.7 ms, sys: 787 Âµs, total: 73.5 ms\n",
      "Wall time: 72.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sales = downcast(df_sales)\n",
    "df_cal = downcast(df_cal)\n",
    "df_price = downcast(df_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Data Transformation & Feature Creation\n",
    "- Convert the sales data from wide to long format\n",
    "- Create lag and rolling window based statistical features on sales\n",
    "- Merge the dataframes\n",
    "- Create price lag and price change features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id  d  sales\n",
       "0  14370     1437        3       1         0         0  1      0\n",
       "1  14380     1438        3       1         0         0  1      0\n",
       "2  14390     1439        3       1         0         0  1      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Melting the sales dataframe\n",
    "df_long = pd.melt(df_sales, id_vars = [c for c in df_sales.columns if type(c)==str], var_name='d', value_name='sales')\n",
    "df_long.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60034810 entries, 0 to 60034809\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   d       object\n",
      "dtypes: object(1)\n",
      "memory usage: 458.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#noticed that 'd' feature is converted to object dtype after melting, so fixed that\n",
    "print(df_long[['d']].info())\n",
    "df_long['d'] = pd.to_numeric(df_long['d']).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 10/10 [00:36<00:00,  3.60s/it]\n",
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 8/8 [03:51<00:00, 28.94s/it]\n"
     ]
    }
   ],
   "source": [
    "#Create features based on historical sales data\n",
    "lags = [28, 30, 31, 35, 42, 49, 56, 63, 70, 77]\n",
    "\n",
    "for lag in tqdm(lags):\n",
    "    df_long[f'lag_{lag}'] = df_long.groupby([\"id\"])['sales'].shift(lag).astype('float16')\n",
    "    \n",
    "    \n",
    "windows = [7, 14, 28, 30, 45, 60, 90, 120]\n",
    "\n",
    "for window in tqdm(windows):\n",
    "    df_long[f\"rmean_28_{window}\"] = df_long.groupby([\"id\"])[\"lag_28\"].transform(lambda x: x.rolling(window).mean()).astype('float16')\n",
    "    \n",
    "    #alternative:\n",
    "    #df_long[f\"rmean_28_{window}\"] = df_long.groupby([\"id\"]).transform(lambda x: x.shift(28).rolling(window).mean()).astype('float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Questions\n",
    "Why did we create sales lags of 28 days or more?\n",
    "- The reason we limit ourselves to create sales lags which are lesser than 28 days is that it may cause data leakage. Our forecasting horizon is 28 and suppose if we create a sales lag feature of 7 days which is a value smaller than our horizon then for days which come after the first 7 days in horizon, logically we are creating sales lag using sales value on a day which falls in the horizon and our whole purpose is to create a model which can forecast 28 days in future so in real scenarios we do not have future sales data at our expense to create any lag features which are lesser than 28 days. (read that again)\n",
    "\n",
    "Why did we create rolling mean feature based on lag_28 feature? \n",
    "- Rolling mean is the average sales over a specific time window where in the window keeps shifting. The reason why we use lag_28 to create rolling mean features is the same as previous question's answer. Any value lesser than 28 days would cause data leakage therefore to avoid this we create the rolling means over the closest lag feature available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dataframes\n",
    "df_long = pd.merge(df_long, df_cal.drop(columns=['weekday']), how='left', on='d')\n",
    "df_long = pd.merge(df_long, df_price.drop(columns=['store_id', 'item_id']), how='left', on=['id', 'wm_yr_wk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create features based on historical price data\n",
    "df_long['price_shift_t1'] = df_long.groupby(['id'])['sell_price'].shift(1)\n",
    "df_long['price_change_t1'] = (df_long['sell_price'] - df_long['price_shift_t1'])/df_long['price_shift_t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068    1069\n",
       "Name: d, dtype: int16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the 'd' value on 1st Jan'14\n",
    "df_cal[df_cal['date']=='2014-01-01']['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retain data after 'd' = 1069\n",
    "df_long = (df_long[df_long['d']>=1069]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sell_price         939011\n",
       "price_shift_t1     943562\n",
       "price_change_t1    943562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check columns with null values\n",
    "df_long.isnull().sum()[df_long.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with 0 \n",
    "for feat in ['sell_price','price_shift_t1','price_change_t1']:\n",
    "    df_long[feat] = df_long[feat].replace(np.nan, 0)\n",
    "\n",
    "#convert dtype of lag columns to 'int16', now that all the initial NaN rows are dropped\n",
    "for feat in [\"lag_28\", \"lag_30\", \"lag_31\", \"lag_35\", \"lag_42\", \"lag_49\", \"lag_56\", \"lag_63\", \"lag_70\", \"lag_77\"]:\n",
    "    df_long[feat] = df_long[feat].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>lag_30</th>\n",
       "      <th>...</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>quarter</th>\n",
       "      <th>week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_shift_t1</th>\n",
       "      <th>price_change_t1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.080078</td>\n",
       "      <td>3.080078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id     d  sales  lag_28  \\\n",
       "0  14370     1437        3       1         0         0  1069      1       1   \n",
       "1  14380     1438        3       1         0         0  1069      0       0   \n",
       "2  14390     1439        3       1         0         0  1069      0       0   \n",
       "3  14400     1440        3       1         0         0  1069      2       1   \n",
       "4  14410     1441        3       1         0         0  1069      1       1   \n",
       "\n",
       "   lag_30  ...  snap_CA  snap_TX  snap_WI  quarter  week  day_of_month  \\\n",
       "0       1  ...        1        1        0        1     1             1   \n",
       "1       0  ...        1        1        0        1     1             1   \n",
       "2       0  ...        1        1        0        1     1             1   \n",
       "3       3  ...        1        1        0        1     1             1   \n",
       "4       1  ...        1        1        0        1     1             1   \n",
       "\n",
       "   is_weekend  sell_price  price_shift_t1  price_change_t1  \n",
       "0           0    8.257812        8.257812              0.0  \n",
       "1           0    3.970703        3.970703              0.0  \n",
       "2           0    0.000000        0.000000              0.0  \n",
       "3           0    4.640625        4.640625              0.0  \n",
       "4           0    3.080078        3.080078              0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the final dataframe\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Save the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = downcast(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.to_pickle(\"preprocessed_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. References\n",
    "\n",
    "- https://www.analyticsvidhya.com/blog/2019/12/6-powerful-feature-engineering-techniques-time-series/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WE8ytMihniG8",
    "uaWM5P2XDmQB",
    "pDcAAba1DvMA",
    "ZC2d97zm7dW9",
    "TGCvkLPqbO2J"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
